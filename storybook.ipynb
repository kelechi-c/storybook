{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "storybook",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install -q diffusers"
      ],
      "metadata": {
        "trusted": true,
        "id": "OnUwOqCj7YEo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from diffusers import FluxPipeline"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "LRAbBnPC7YEw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-schnell\", torch_dtype=torch.bfloat16)#.to(\"cuda\")\n",
        "# pipe.enable_model_cpu_offload() #save some VRAM by offloading the model to CPU. Remove this if you have enough GPU power"
      ],
      "metadata": {
        "trusted": true,
        "id": "LQc7dzhy7YEx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# pipe.save_pretrained('flux_schnell')"
      ],
      "metadata": {
        "trusted": true,
        "id": "0yfvOtVN7YEz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt = \"space photograph of a blue bird falling throught the atmosphere, with the rising sun in the horizon, in the background.jpg\"\n",
        "# image = pipe(\n",
        "#     prompt,\n",
        "#     guidance_scale=0.0,\n",
        "#     num_inference_steps=5,\n",
        "#     max_sequence_length=256,\n",
        "#     generator=torch.Generator(\"cpu\").manual_seed(0)\n",
        "# ).images[0]\n",
        "\n",
        "# image"
      ],
      "metadata": {
        "trusted": true,
        "id": "Bq5amFzF7YE0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# image.save(\"flux-schnell.png\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "JYGbSjNG7YE1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## using Stable diffusion cascade"
      ],
      "metadata": {
        "id": "t2GFlPFi7YFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import (\n",
        "    StableCascadeDecoderPipeline,\n",
        "    StableCascadePriorPipeline,\n",
        "    StableCascadeUNet,\n",
        ")\n",
        "\n",
        "prompt = \"an image of a white snowflake falling through space\"\n",
        "negative_prompt = \"\"\n",
        "\n",
        "prior_unet = StableCascadeUNet.from_pretrained(\"stabilityai/stable-cascade-prior\", subfolder=\"prior_lite\")\n",
        "decoder_unet = StableCascadeUNet.from_pretrained(\"stabilityai/stable-cascade\", subfolder=\"decoder_lite\")\n",
        "\n",
        "prior_unet.save_pretrained('stable_cascade_prior_unet')\n",
        "decoder_unet.save_pretrained('stable_cascade_decoder_unet')"
      ],
      "metadata": {
        "trusted": true,
        "id": "xLR8WwBL7YFK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "prior = StableCascadePriorPipeline.from_pretrained(\"stabilityai/stable-cascade-prior\", prior=prior_unet)\n",
        "decoder = StableCascadeDecoderPipeline.from_pretrained(\"stabilityai/stable-cascade\", decoder=decoder_unet)\n",
        "\n",
        "decoder.save_pretrained('stable_cascade_decoder')\n",
        "prior.save_pretrained('stable_cascade_prior')\n",
        "\n",
        "prior.enable_model_cpu_offload()\n",
        "prior_output = prior(\n",
        "    prompt=prompt,\n",
        "    height=1024,\n",
        "    width=1024,\n",
        "    negative_prompt=negative_prompt,\n",
        "    guidance_scale=4.0,\n",
        "    num_images_per_prompt=1,\n",
        "    num_inference_steps=20\n",
        ")\n",
        "\n",
        "prior_output"
      ],
      "metadata": {
        "trusted": true,
        "id": "oHLbYfxJ7YFL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "decoder.enable_model_cpu_offload()\n",
        "decoder_output = decoder(\n",
        "    image_embeddings=prior_output.image_embeddings,\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    guidance_scale=0.0,\n",
        "    output_type=\"pil\",\n",
        "    num_inference_steps=10\n",
        ").images[0]\n",
        "\n",
        "decoder_output"
      ],
      "metadata": {
        "trusted": true,
        "id": "vfLDCyVy7YFM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_output.save(\"cascade.png\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "SwabQW4R7YFN"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}